<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Diffusion Models: Theory and Applications in Earth Sciences | ESS-AI/ML</title><meta name=keywords content="Diffusion Model"><meta name=description content="A beginner’s guide to diffusion models"><meta name=author content="ESS-AIML"><link rel=canonical href=https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/><link crossorigin=anonymous href=/blogs/assets/css/stylesheet.e4604635c299f5b76ed8970ceeb86365464445b38b278c180365e0737c950806.css integrity="sha256-5GBGNcKZ9bdu2JcM7rhjZUZERbOLJ4wYA2Xgc3yVCAY=" rel="preload stylesheet" as=style><link rel=icon href=https://ess-aiml.github.io/blogs/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ess-aiml.github.io/blogs/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ess-aiml.github.io/blogs/favicon-32x32.png><link rel=apple-touch-icon href=https://ess-aiml.github.io/blogs/apple-touch-icon.png><link rel=mask-icon href=https://ess-aiml.github.io/blogs/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},svg:{fontCache:"global"}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta property="og:url" content="https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/"><meta property="og:site_name" content="ESS-AI/ML"><meta property="og:title" content="Diffusion Models: Theory and Applications in Earth Sciences"><meta property="og:description" content="A beginner’s guide to diffusion models"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-10-28T00:00:00+00:00"><meta property="article:tag" content="Diffusion Model"><meta property="og:image" content="https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion.jpg"><meta name=twitter:title content="Diffusion Models: Theory and Applications in Earth Sciences"><meta name=twitter:description content="A beginner’s guide to diffusion models"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ess-aiml.github.io/blogs/posts/"},{"@type":"ListItem","position":2,"name":"Diffusion Models: Theory and Applications in Earth Sciences","item":"https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Diffusion Models: Theory and Applications in Earth Sciences","name":"Diffusion Models: Theory and Applications in Earth Sciences","description":"A beginner’s guide to diffusion models","keywords":["Diffusion Model"],"articleBody":"In the past few years, diffusion models have become one of the most powerful tools in artificial intelligence (AI). They’re behind many impressive generative systems — from creating realistic images, sounds, and videos to helping design new molecules and drugs to modeling complex climate and environmental systems.\nThere are already plenty of great articles that dive into the technical details of diffusion models — and we’ll share some of our favorites along the way. In this post, we focus on the core principles and explore how diffusion models are being used in environmental system science, and why those applications are so promising and exciting.\nLet’s get started!\nWhat are generative models? Generative models are AI systems that can learn the underlying structure of existing data and use it to create new content similar to the originals.\nWhat does this mean in practice? Suppose we have a dataset containing photos of dogs. We can train a generative model on this dataset to capture the rules that govern the complex relationships between pixels in images of dogs. Then we can sample from this model to create novel, realistic images of dogs that did not exist in the original dataset. Generative models are also probabilistic systems – that means they are able to sample many different variations of the output, rather than get the same output every time.\nFigure 1: Generative model learns features of dogs from the training dataset and can generate new, high-quality dog images. Credit: Tanishq Mathew Abraham.\nThere are different types of generative models, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and flow-based and diffusion models. They have shown great success in generating high-quality samples, but each has some limitations of its own. We only discuss diffusion models here.\nFigure 2: Overview of different types of generative models.\nWhat are diffusion models? Diffusion models are inspired by non-equilibrium thermodynamics in physics. The core idea behind them is simple: we gradually corrupt (add noise to) clean data until it becomes completely random, then train a deep learning model to reverse this process and recover the original data.\nDiffusion models are a class of generative models that learn to reverse a gradual noising process applied to data, enabling them to generate realistic samples from the underlying data distributions by iteratively denoising random noise.\nIn other words, diffusion models learn how to “undo” noise — like taking a blurry satellite image and sharpening it bit by bit until the continents and clouds come back into focus. Each small step improves the image, gradually turning random noise into something realistic. This process has two parts:\nForward diffusion: adding noise to the data in many small steps. Reverse diffusion: training the model to remove the noise and rebuild the data. Figure 3: Forward and reverse diffusion processes. Source: Yang et al (2022)\nIn principle, if we start from pure random (e.g., white) noise, we should be able to keep applying the trained model until we obtain a sample that looks as if it were drawn from the training set. That’s it – and yet this simple idea works incredibly well in practice.\nFor those who want to explore further:\nThis article provides an interactive, step-by-step introduction that makes diffusion models much easier to grasp. This post dives into the math behind both the forward and reverse diffusion processes. Both of these resources are well worth a read if you’d like to dig into the details.\nHow do diffusion models work? Let’s look at the simplified math of diffusion models\nForward Diffusion – adding noise: Suppose we have a sample $\\mathbf{x}_0$ that we want to corrupt gradually so that eventually it is indistinguishable from random noise. Here are the fundamental steps we will do:\nDefine a function $q$ that adds a small amount of Gaussian noise with variance $\\beta_t$ to sample $\\mathbf{x}_{t-1}$ to create sample $\\mathbf{x}_{t}$. Keep applying this function will generate a sequence of progressively noisier samples $(\\mathbf{x}_{0},…, \\mathbf{x}_{T})$ …\n","wordCount":"658","inLanguage":"en","image":"https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion.jpg","datePublished":"2025-10-28T00:00:00Z","dateModified":"2025-10-28T00:00:00Z","author":{"@type":"Person","name":"ESS-AIML"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/"},"publisher":{"@type":"Organization","name":"ESS-AI/ML","logo":{"@type":"ImageObject","url":"https://ess-aiml.github.io/blogs/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ess-aiml.github.io/blogs/ accesskey=h title="ESS-AI/ML (Alt + H)">ESS-AI/ML</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ess-aiml.github.io/blogs/posts title=Posts><span>Posts</span></a></li><li><a href=https://ess-aiml.github.io/blogs/stories title=Stories><span>Stories</span></a></li><li><a href=https://ess-aiml.github.io/blogs/tutorials title=Tutorials><span>Tutorials</span></a></li><li><a href=https://ess-aiml.github.io/blogs/archives title=Archive><span>Archive</span></a></li><li><a href=https://ess-aiml.github.io/blogs/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://ess-aiml.github.io/blogs/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ess-aiml.github.io/blogs/>Home</a>&nbsp;»&nbsp;<a href=https://ess-aiml.github.io/blogs/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Diffusion Models: Theory and Applications in Earth Sciences</h1><div class=post-meta><span title='2025-10-28 00:00:00 +0000 UTC'>October 28, 2025</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>658 words</span>&nbsp;·&nbsp;<span>ESS-AIML</span>&nbsp;|&nbsp;<span>
<a href=https://github.com/ess-aiml/blogs/blob/main/content/posts/Intro-Diffusion-Models/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></span></div></header><figure class=entry-cover><img loading=eager srcset='https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion_hu_352f95df6bded65e.jpg 360w,https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion_hu_66a2801a960f51d6.jpg 480w,https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion_hu_7a0ac690c1912db.jpg 720w,https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion_hu_dac70d87af8e7db7.jpg 1080w,https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion_hu_4069a8abb3b86a25.jpg 1500w,https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion.jpg 1536w' src=https://ess-aiml.github.io/blogs/posts/intro-diffusion-models/images/Earth_diffusion.jpg sizes="(min-width: 768px) 720px, 100vw" width=1536 height=1024 alt><figcaption>Photo created by Text-to-Image AI</figcaption></figure><div class=post-content><p>In the past few years, <strong>diffusion models</strong> have become one of the most powerful tools in artificial intelligence (AI). They’re behind many impressive <strong>generative systems</strong> — from creating realistic images, sounds, and videos to helping design new molecules and drugs to modeling complex climate and environmental systems.</p><p>There are already plenty of great articles that dive into the technical details of diffusion models — and we’ll share some of our favorites along the way. In this post, we focus on the core principles and explore how diffusion models are being used in environmental system science, and why those applications are so promising and exciting.</p><p>Let’s get started!</p><h2 id=what-are-generative-models>What are generative models?<a hidden class=anchor aria-hidden=true href=#what-are-generative-models>#</a></h2><blockquote><p><em>Generative models are AI systems that can learn the underlying structure of existing data and use it to create new content similar to the originals.</em></p></blockquote><p>What does this mean in practice? Suppose we have a dataset containing photos of dogs. We can train a generative model on this dataset to capture the rules that govern the complex relationships between pixels in images of dogs. Then we can sample from this model to create novel, realistic images of dogs that did not exist in the original dataset.
Generative models are also <strong>probabilistic systems</strong> &ndash; that means they are able to sample many different variations of the output, rather than get the same output every time.</p><figure><img loading=lazy src=images/generative_modeling.jpg alt=Generative><figcaption><p>Figure 1: Generative model learns features of dogs from the training dataset and can generate new, high-quality dog images. Credit: Tanishq Mathew Abraham.</p></figcaption></figure><p>There are different types of generative models, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and flow-based and diffusion models. They have shown great success in generating high-quality samples, but each has some limitations of its own. We only discuss diffusion models here.</p><figure><img loading=lazy src=https://lilianweng.github.io/posts/2021-07-11-diffusion-models/generative-overview.png alt=Generative><figcaption><p>Figure 2: Overview of different types of generative models.</p></figcaption></figure><h2 id=what-are-diffusion-models>What are diffusion models?<a hidden class=anchor aria-hidden=true href=#what-are-diffusion-models>#</a></h2><p>Diffusion models are inspired by non-equilibrium thermodynamics in physics. The core idea behind them is simple: we gradually corrupt (add noise to) clean data until it becomes completely random, then train a deep learning model to reverse this process and recover the original data.</p><blockquote><p><em>Diffusion models are a class of generative models that learn to reverse a gradual noising process applied to data, enabling them to generate realistic samples from the underlying data distributions by iteratively denoising random noise.</em></p></blockquote><p>In other words, diffusion models learn how to &ldquo;undo&rdquo; noise — like taking a blurry satellite image and sharpening it bit by bit until the continents and clouds come back into focus. Each small step improves the image, gradually turning random noise into something realistic.
This process has two parts:</p><ul><li><strong>Forward diffusion</strong>: adding noise to the data in many small steps.</li><li><strong>Reverse diffusion</strong>: training the model to remove the noise and rebuild the data.</li></ul><figure><img loading=lazy src=images/diffusion_processes.webp alt="Diffusion model"><figcaption><p>Figure 3: Forward and reverse diffusion processes. Source: <a href=https://arxiv.org/abs/2209.00796>Yang et al (2022)</a></p></figcaption></figure><p>In principle, if we start from pure random (e.g., white) noise, we should be able to keep applying the trained model until we obtain a sample that looks as if it were drawn from the training set. That&rsquo;s it &ndash; and yet this simple idea works incredibly well in practice.</p><p>For those who want to explore further:</p><ul><li>This <strong><a href=https://erdem.pl/2023/11/step-by-step-visual-introduction-to-diffusion-models>article</a></strong> provides an interactive, step-by-step introduction that makes diffusion models much easier to grasp.</li><li>This <strong><a href=https://lilianweng.github.io/posts/2021-07-11-diffusion-models/>post</a></strong> dives into the math behind both the forward and reverse diffusion processes.</li></ul><p>Both of these resources are well worth a read if you’d like to dig into the details.</p><h2 id=how-do-diffusion-models-work>How do diffusion models work?<a hidden class=anchor aria-hidden=true href=#how-do-diffusion-models-work>#</a></h2><p>Let&rsquo;s look at the simplified math of diffusion models</p><h3 id=forward-diffusion--adding-noise>Forward Diffusion &ndash; adding noise:<a hidden class=anchor aria-hidden=true href=#forward-diffusion--adding-noise>#</a></h3><p>Suppose we have a sample $\mathbf{x}_0$ that we want to corrupt gradually so that eventually it is indistinguishable from random noise. Here are the fundamental steps we will do:</p><ul><li>Define a function $q$ that adds a small amount of Gaussian noise with variance $\beta_t$ to sample $\mathbf{x}_{t-1}$ to create sample $\mathbf{x}_{t}$.</li><li>Keep applying this function will generate a sequence of progressively noisier samples $(\mathbf{x}_{0},&mldr;, \mathbf{x}_{T})$</li></ul><p>&mldr;</p><!--### Reverse Diffusion:--><!--### Diffusion models in environmental system science?--></div><footer class=post-footer><ul class=post-tags><li><a href=https://ess-aiml.github.io/blogs/tags/diffusion-model/>Diffusion Model</a></li></ul><nav class=paginav><a class=next href=https://ess-aiml.github.io/blogs/posts/earth-foundational-models-part1/><span class=title>Next »</span><br><span>Foundation Models for Earth System - An Introduction</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ess-aiml.github.io/blogs/>ESS-AI/ML</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>